# Minimal AWS Deployment Guide - CIFAR-10 CNN Project

Ten przewodnik opisuje jak wdroÅ¼yÄ‡ projekt CIFAR-10 CNN na AWS z **minimalnÄ… konfiguracjÄ…** - tylko 3 usÅ‚ugi AWS zamiast 10+.

## ğŸ¯ Minimalna architektura

**Tylko 3 usÅ‚ugi AWS:**
1. **EC2** - jedna instancja z wszystkimi usÅ‚ugami (API + MLflow)
2. **S3** - jeden bucket dla modeli i MLflow artifacts  
3. **SageMaker** - tylko do trenowania (pay-per-use)

**FunkcjonalnoÅ›ci:**
1. **WEBAPI CIFAR-10** - FastAPI na EC2 (port 8000)
2. **MLflow** - lokalny serwer na EC2 z SQLite (port 5000)
3. **Trenowanie modeli** - SageMaker jobs (pay-per-use)

## ğŸ’° Koszty

**Szacowany koszt: ~$15-25/miesiÄ…c + SageMaker (tylko podczas trenowania)**

- **EC2 t3.medium**: ~$30/miesiÄ…c
- **S3**: ~$1-5/miesiÄ…c (w zaleÅ¼noÅ›ci od uÅ¼ycia)
- **SageMaker**: Pay-per-use (tylko podczas trenowania)
- **Elastic IP**: ~$3.6/miesiÄ…c

**OszczÄ™dnoÅ›Ä‡: ~$50-80/miesiÄ…c** w porÃ³wnaniu do poprzedniej konfiguracji!

## ğŸ“‹ Wymagania

### Lokalne wymagania:
- AWS CLI skonfigurowany z odpowiednimi uprawnieniami
- Terraform >= 1.0
- SSH key pair
- Docker (opcjonalnie, do testowania lokalnie)

### Uprawnienia AWS:
- EC2FullAccess
- S3FullAccess  
- SageMakerFullAccess
- IAMFullAccess (do tworzenia rÃ³l)

## ğŸš€ Szybki start

### 1. Przygotowanie

```bash
# PrzejdÅº do katalogu z minimalnÄ… konfiguracjÄ…
cd infra/aws/terraform-minimal

# Skopiuj przykÅ‚adowy plik zmiennych
cp terraform.tfvars.example terraform.tfvars
```

### 2. Konfiguracja SSH

```bash
# Wygeneruj klucz SSH (jeÅ›li nie masz)
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"

# Skopiuj klucz publiczny do terraform.tfvars
cat ~/.ssh/id_rsa.pub
```

### 3. Edycja konfiguracji

Edytuj `terraform.tfvars`:

```hcl
aws_region = "us-east-1"
environment = "dev"
vpc_cidr = "10.0.0.0/16"
public_subnet_cidr = "10.0.1.0/24"

# EC2 Configuration
ec2_ami = "ami-0c02fb55956c7d316"  # Ubuntu 22.04 LTS
ec2_instance_type = "t3.medium"    # 2 vCPU, 4GB RAM
ec2_volume_size = 30               # 30GB storage

# SSH Public Key (wklej swÃ³j klucz publiczny)
ssh_public_key = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQ... your_email@example.com"
```

### 4. WdroÅ¼enie infrastruktury

```bash
# Inicjalizacja Terraform
terraform init

# Plan wdroÅ¼enia
terraform plan

# WdroÅ¼enie
terraform apply
```

### 5. Konfiguracja aplikacji na EC2

```bash
# PoÅ‚Ä…cz siÄ™ z instancjÄ… EC2
ssh -i ~/.ssh/id_rsa ubuntu@<EC2_PUBLIC_IP>

# SprawdÅº czy usÅ‚ugi siÄ™ uruchomiÅ‚y
cd /home/ubuntu/cifar-cnn
docker-compose ps

# JeÅ›li nie, uruchom rÄ™cznie
docker-compose up -d

# SprawdÅº logi
docker-compose logs -f
```

### 6. Test wdroÅ¼enia

```bash
# SprawdÅº API
curl http://<EC2_PUBLIC_IP>:8000/api/health

# SprawdÅº MLflow
curl http://<EC2_PUBLIC_IP>:5000

# SprawdÅº status usÅ‚ug
./health_check.sh
```

## ğŸ”§ ZarzÄ…dzanie usÅ‚ugami

### Restart usÅ‚ug

```bash
# Na EC2
cd /home/ubuntu/cifar-cnn
docker-compose restart

# Lub restart caÅ‚ego systemu
sudo systemctl restart cifar-cnn
```

### Aktualizacja aplikacji

```bash
# Na EC2
cd /home/ubuntu/cifar-cnn
git pull  # jeÅ›li uÅ¼ywasz git
docker-compose build
docker-compose up -d
```

### Sprawdzanie logÃ³w

```bash
# Logi API
docker-compose logs api

# Logi MLflow
docker-compose logs mlflow

# Logi systemowe
sudo journalctl -u cifar-cnn -f
```

## ğŸ¯ Trenowanie modeli na SageMaker

### 1. Przygotowanie danych treningowych

```bash
# Na EC2, wgraj dane do S3
aws s3 cp data/raw/cifar-10-python.tar.gz s3://<S3_BUCKET>/training-data/
```

### 2. Uruchomienie trenowania

```bash
# Na EC2
python sagemaker-training.py start \
  --s3-bucket <S3_BUCKET> \
  --model-type base_cnn \
  --epochs 50 \
  --instance-type ml.m5.large
```

### 3. Monitorowanie trenowania

```bash
# Lista zadaÅ„ treningowych
python sagemaker-training.py list

# SzczegÃ³Å‚y zadania
python sagemaker-training.py describe --job-name <JOB_NAME>

# Oczekiwanie na zakoÅ„czenie
python sagemaker-training.py wait --job-name <JOB_NAME>
```

### 4. Sprawdzanie wynikÃ³w w MLflow

OtwÃ³rz w przeglÄ…darce: `http://<EC2_PUBLIC_IP>:5000`

## ğŸ“Š MLflow Integration

### Konfiguracja MLflow

MLflow jest automatycznie skonfigurowany z:
- **Backend Store**: SQLite (lokalny plik)
- **Artifact Store**: S3 bucket
- **Tracking URI**: `http://<EC2_PUBLIC_IP>:5000`

### Logowanie eksperymentÃ³w

```python
import mlflow
import mlflow.tensorflow

# Ustaw tracking URI
mlflow.set_tracking_uri("http://<EC2_PUBLIC_IP>:5000")

# Rozpocznij eksperyment
with mlflow.start_run():
    # Loguj parametry
    mlflow.log_param("epochs", 50)
    mlflow.log_param("batch_size", 32)
    
    # Loguj metryki
    mlflow.log_metric("accuracy", 0.85)
    mlflow.log_metric("loss", 0.45)
    
    # Loguj model
    mlflow.tensorflow.log_model(model, "model")
```

## ğŸ” Monitorowanie

### Health Checks

```bash
# SprawdÅº zdrowie API
curl http://<EC2_PUBLIC_IP>:8000/api/health

# SprawdÅº zdrowie MLflow
curl http://<EC2_PUBLIC_IP>:5000/health

# SprawdÅº status Docker
docker-compose ps
```

### Logi systemowe

```bash
# Logi aplikacji
sudo journalctl -u cifar-cnn -f

# Logi Docker
docker-compose logs -f

# Logi systemowe
sudo tail -f /var/log/syslog
```

## ğŸ› ï¸ RozwiÄ…zywanie problemÃ³w

### CzÄ™ste problemy:

1. **BÅ‚Ä…d poÅ‚Ä…czenia SSH**
   ```bash
   # SprawdÅº security group
   aws ec2 describe-security-groups --group-ids <sg-id>
   
   # SprawdÅº klucz SSH
   ssh -i ~/.ssh/id_rsa -v ubuntu@<EC2_PUBLIC_IP>
   ```

2. **UsÅ‚ugi nie uruchamiajÄ… siÄ™**
   ```bash
   # SprawdÅº logi Docker
   docker-compose logs
   
   # SprawdÅº status kontenerÃ³w
   docker-compose ps
   
   # Restart usÅ‚ug
   docker-compose restart
   ```

3. **BÅ‚Ä…d poÅ‚Ä…czenia z S3**
   ```bash
   # SprawdÅº uprawnienia IAM
   aws sts get-caller-identity
   
   # Test poÅ‚Ä…czenia S3
   aws s3 ls s3://<S3_BUCKET>
   ```

4. **BÅ‚Ä…d trenowania SageMaker**
   ```bash
   # SprawdÅº logi trenowania
   aws logs describe-log-streams \
     --log-group-name "/aws/sagemaker/TrainingJobs/<job-name>"
   ```

### Debugowanie:

```bash
# SprawdÅº status Terraform
terraform show

# SprawdÅº status EC2
aws ec2 describe-instances --instance-ids <instance-id>

# SprawdÅº status S3
aws s3 ls s3://<S3_BUCKET>
```

## ğŸ”„ Backup i przywracanie

### Backup danych

```bash
# Backup MLflow bazy danych
docker-compose exec mlflow cp /mlflow/mlflow.db /mlflow/backup-$(date +%Y%m%d).db

# Backup modeli
aws s3 sync s3://<S3_BUCKET>/models/ ./backup/models/
```

### Przywracanie

```bash
# PrzywrÃ³Ä‡ MLflow bazÄ™ danych
docker-compose exec mlflow cp /mlflow/backup-YYYYMMDD.db /mlflow/mlflow.db

# PrzywrÃ³Ä‡ modele
aws s3 sync ./backup/models/ s3://<S3_BUCKET>/models/
```

## ğŸ—‘ï¸ Usuwanie zasobÃ³w

**UWAGA**: PamiÄ™taj o usuniÄ™ciu zasobÃ³w po zakoÅ„czeniu pracy, aby uniknÄ…Ä‡ niepotrzebnych kosztÃ³w:

```bash
# UsuÅ„ infrastrukturÄ™
cd infra/aws/terraform-minimal
terraform destroy

# PotwierdÅº usuniÄ™cie wpisujÄ…c 'yes'
```

## ğŸ“š Dodatkowe zasoby

- [AWS EC2 Documentation](https://docs.aws.amazon.com/ec2/)
- [SageMaker Documentation](https://docs.aws.amazon.com/sagemaker/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest)

## ğŸ¤ Wsparcie

W przypadku problemÃ³w:
1. SprawdÅº logi Docker: `docker-compose logs`
2. SprawdÅº status EC2 w AWS Console
3. SprawdÅº dokumentacjÄ™ AWS
4. UtwÃ³rz issue w repozytorium

---

**Uwaga**: Ta minimalna konfiguracja jest idealna do developmentu i testowania. Dla produkcji rozwaÅ¼ dodanie:
- Load Balancer
- RDS zamiast SQLite
- WiÄ™kszej instancji EC2
- Backup strategii






















