# syntax=docker/dockerfile:1.4
# MLflow server Dockerfile for AWS deployment
FROM python:3.12-slim

# Set working directory
WORKDIR /mlflow

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db \
    MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://cifar-cnn-mlflow-artifacts \
    AWS_DEFAULT_REGION=us-east-1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    bash \
    sqlite3 \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Copy dependency spec first to leverage Docker layer cache
COPY requirements-mlflow.txt /tmp/requirements-mlflow.txt

# Install Python dependencies (cache wheels between builds)
RUN pip install --no-cache-dir --upgrade pip
RUN --mount=type=cache,target=/root/.cache/pip pip install --no-cache-dir -r /tmp/requirements-mlflow.txt

# Create necessary directories
RUN mkdir -p /mlflow/mlruns /mlflow/artifacts

# Create startup script
COPY <<EOF /mlflow/start.sh
#!/bin/bash
set -e
echo "Starting MLflow server..."
echo "Backend URI: \$MLFLOW_BACKEND_STORE_URI"
echo "Artifact Root: \$MLFLOW_DEFAULT_ARTIFACT_ROOT"
echo "AWS Region: \$AWS_DEFAULT_REGION"

# Initialize database if using SQLite
if [[ "\$MLFLOW_BACKEND_STORE_URI" == sqlite* ]]; then
    echo "Initializing SQLite database..."
    mlflow db upgrade \$MLFLOW_BACKEND_STORE_URI
fi

# Start MLflow server
exec mlflow server \\
    --backend-store-uri "\$MLFLOW_BACKEND_STORE_URI" \\
    --default-artifact-root "\$MLFLOW_DEFAULT_ARTIFACT_ROOT" \\
    --host 0.0.0.0 \\
    --port 5000 \\
    --serve-artifacts
EOF

RUN chmod +x /mlflow/start.sh

# Expose port
EXPOSE 5000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

# Run MLflow server
CMD ["/mlflow/start.sh"]

